{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written station data for year 1905\n",
      "Written station data for year 1906\n",
      "Written station data for year 1907\n",
      "Written station data for year 1908\n",
      "Written station data for year 1909\n",
      "Written station data for year 1910\n",
      "Written station data for year 1911\n",
      "Written station data for year 1912\n",
      "Written station data for year 1913\n",
      "Written station data for year 1914\n",
      "Written station data for year 1915\n",
      "Written station data for year 1916\n",
      "Written station data for year 1917\n",
      "Written station data for year 1918\n",
      "Written station data for year 1919\n",
      "Written station data for year 1920\n",
      "Written station data for year 1921\n",
      "Written station data for year 1922\n",
      "Written station data for year 1923\n",
      "Written station data for year 1924\n",
      "Written station data for year 1925\n",
      "Written station data for year 1926\n",
      "Written station data for year 1927\n",
      "Written station data for year 1928\n",
      "Written station data for year 1929\n",
      "Written station data for year 1930\n",
      "Written station data for year 1931\n",
      "Written station data for year 1932\n",
      "Written station data for year 1933\n",
      "Written station data for year 1934\n",
      "Written station data for year 1935\n",
      "Written station data for year 1936\n",
      "Written station data for year 1937\n",
      "Written station data for year 1938\n",
      "Written station data for year 1939\n",
      "Written station data for year 1940\n",
      "Written station data for year 1941\n",
      "Written station data for year 1942\n",
      "Written station data for year 1943\n",
      "Written station data for year 1944\n",
      "Written station data for year 1945\n",
      "Written station data for year 1946\n",
      "Written station data for year 1947\n",
      "Written station data for year 1948\n",
      "Written station data for year 1949\n",
      "Written station data for year 1950\n",
      "Written station data for year 1951\n",
      "Written station data for year 1952\n",
      "Written station data for year 1953\n",
      "Written station data for year 1954\n",
      "Written station data for year 1955\n",
      "Written station data for year 1956\n",
      "Written station data for year 1957\n",
      "Written station data for year 1958\n",
      "Written station data for year 1959\n",
      "Written station data for year 1960\n",
      "Written station data for year 1961\n",
      "Written station data for year 1962\n",
      "Written station data for year 1963\n",
      "Written station data for year 1964\n",
      "Written station data for year 1965\n",
      "Written station data for year 1966\n",
      "Written station data for year 1967\n",
      "Written station data for year 1968\n",
      "Written station data for year 1969\n",
      "Written station data for year 1970\n",
      "Written station data for year 1971\n",
      "Written station data for year 1972\n",
      "Written station data for year 1973\n",
      "Written station data for year 1974\n",
      "Written station data for year 1975\n",
      "Written station data for year 1976\n",
      "Written station data for year 1977\n",
      "Written station data for year 1978\n",
      "Written station data for year 1979\n",
      "Written station data for year 1980\n",
      "Written station data for year 1981\n",
      "Written station data for year 1982\n",
      "Written station data for year 1983\n",
      "Written station data for year 1984\n",
      "Written station data for year 1985\n",
      "Written station data for year 1986\n",
      "Written station data for year 1987\n",
      "Written station data for year 1988\n",
      "Written station data for year 1989\n",
      "Written station data for year 1990\n",
      "Written station data for year 1991\n",
      "Written station data for year 1992\n",
      "Written station data for year 1993\n",
      "Written station data for year 1994\n",
      "Written station data for year 1995\n",
      "Written station data for year 1996\n",
      "Written station data for year 1997\n",
      "Written station data for year 1998\n",
      "Written station data for year 1999\n",
      "Written station data for year 2000\n",
      "Written station data for year 2001\n",
      "Written station data for year 2002\n",
      "Written station data for year 2003\n",
      "Written station data for year 2004\n",
      "Written station data for year 2005\n",
      "Written station data for year 2006\n",
      "Written station data for year 2007\n",
      "Written station data for year 2008\n",
      "Written station data for year 2009\n",
      "Written station data for year 2010\n",
      "Written station data for year 2011\n",
      "Written station data for year 2012\n",
      "Written station data for year 2013\n",
      "Written station data for year 2014\n",
      "Written station data for year 2015\n",
      "Written station data for year 2016\n",
      "Written station data for year 2017\n",
      "Written station data for year 2018\n",
      "Written station data for year 2019\n"
     ]
    }
   ],
   "source": [
    "for x in range(1905, 2020):\n",
    "    \n",
    "    \n",
    "    midasEnd = str(x) + \"12\"\n",
    "    midasStart = str(x) + \"01\"\n",
    "    \n",
    "    #get data\n",
    "    airData = pd.read_csv(\"airCSVData/midas_tempdrnl_\"+midasStart+\"-\"+midasEnd+\".csv\",sep=r'\\s*,\\s*',\n",
    "                           header=0, encoding='ascii', engine='python')\n",
    "    soilData = pd.read_csv(\"soilCSVData/midas_soiltemp_\"+midasStart+\"-\"+midasEnd+\".csv\",sep=r'\\s*,\\s*',\n",
    "                           header=0, encoding='ascii', engine='python')\n",
    "    \n",
    "    #print(\"got midas \"+midasStart+\"-\"+midasEnd+\".csv\")\n",
    "    \n",
    "    #remove unnedded columns\n",
    "    airDataS = airData.drop(columns = ['MAX_AIR_TEMP_J','MIN_AIR_TEMP_J','MIN_GRSS_TEMP_J','MIN_CONC_TEMP_J',\n",
    "                                 'MAX_AIR_TEMP_Q','MIN_AIR_TEMP_Q','MIN_GRSS_TEMP_Q','MIN_CONC_TEMP_Q',\n",
    "                                 'ID_TYPE','VERSION_NUM','MAX_AIR_TEMP','MIN_AIR_TEMP',\n",
    "                                 'MET_DOMAIN_NAME','ID','MIDAS_STMP_ETIME','MIN_CONC_TEMP','REC_ST_IND',\n",
    "                                 'OB_HOUR_COUNT','METO_STMP_TIME'])\n",
    "    soilData = soilData.drop(columns = ['Q100CM_SOIL_TEMP_J','Q50CM_SOIL_TEMP_J','Q30CM_SOIL_TEMP_J','Q20CM_SOIL_TEMP_J',\n",
    "                        'Q10CM_SOIL_TEMP_J','Q100CM_SOIL_TEMP_Q','Q50CM_SOIL_TEMP_Q','Q30CM_SOIL_TEMP_Q',\n",
    "                        'Q20CM_SOIL_TEMP_Q','Q10CM_SOIL_TEMP_Q','Q5CM_SOIL_TEMP_Q','Q5CM_SOIL_TEMP_J',\n",
    "                        'Q50CM_SOIL_TEMP','Q30CM_SOIL_TEMP','Q20CM_SOIL_TEMP',\n",
    "                        'Q10CM_SOIL_TEMP','Q5CM_SOIL_TEMP', 'ID', 'ID_TYPE', 'MET_DOMAIN_NAME', \n",
    "                        'VERSION_NUM', 'MIDAS_STMP_ETIME','METO_STMP_TIME','REC_ST_IND'])\n",
    "    \n",
    "    #split date/time column\n",
    "    airDataS[['OB_END_DATE','OB_END_TIME']] = airDataS['OB_END_TIME'].str.split(' ',expand=True)\n",
    "    soilData[['OB_DATE','OB_TIME']] = soilData['OB_TIME'].str.split(' ',expand=True)\n",
    "    \n",
    "    #create list of stations with valid data\n",
    "    \n",
    "    \n",
    "    cmTest = (soilData['Q100CM_SOIL_TEMP'] > 0)\n",
    "    \n",
    "    filteredAirSet = airDataS[airDataS.MIN_GRSS_TEMP.notnull()]\n",
    "    filteredSet = soilData[cmTest]\n",
    "    \n",
    "    noOfStationsGrass = filteredAirSet.SRC_ID.unique().tolist()\n",
    "    noOfStationsSoil = filteredSet.SRC_ID.unique().tolist()\n",
    "\n",
    "    bothHaveData = list(set(noOfStationsSoil) & set(noOfStationsGrass))\n",
    "    \n",
    "    stationID = {}\n",
    "\n",
    "    for stationDF in bothHaveData:\n",
    "        stationID[stationDF] = pd.DataFrame(columns = ['OB_TIME','SRC_ID','Q100CM_SOIL_TEMP','OB_DATE','MIN_GRSS_TEMP'])\n",
    "\n",
    "    counter = 0;\n",
    "    start_date = date(x, 1, 1)\n",
    "    end_date = date(x, 12,31)\n",
    "    #12, 31)\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        getDaySoil = filteredSet['OB_DATE'] == single_date.strftime(\"%Y-%m-%d\")\n",
    "        getDayAir = filteredAirSet['OB_END_DATE'] == single_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        for stationNo in bothHaveData:\n",
    "\n",
    "            getStationS = filteredSet['SRC_ID'] == stationNo\n",
    "            getStationA = filteredAirSet['SRC_ID'] == stationNo\n",
    "\n",
    "            stationFilterS = getDaySoil & getStationS\n",
    "            #print(filteredSet[stationFilterS])\n",
    "\n",
    "            stationFilterA = getDayAir & getStationA\n",
    "            #print(filteredAirSet[stationFilterA])\n",
    "            oneValSoil = filteredSet[stationFilterS]\n",
    "            oneValAir = filteredAirSet[stationFilterA]\n",
    "\n",
    "            try:\n",
    "                listForAppend = [oneValSoil['OB_TIME'].values[0],\n",
    "                                        oneValSoil['SRC_ID'].values[0],\n",
    "                                        oneValSoil['Q100CM_SOIL_TEMP'].values[0],\n",
    "                                        oneValSoil['OB_DATE'].values[0],\n",
    "                                        oneValAir['MIN_GRSS_TEMP'].values[0]]\n",
    "\n",
    "                s = pd.Series(listForAppend, index=stationID[stationNo].columns)\n",
    "\n",
    "                stationID[stationNo] = stationID[stationNo].append(s, ignore_index=True)\n",
    "            except:\n",
    "                #print(\"no val \" + str(stationNo))\n",
    "                counter += 1\n",
    "                \n",
    "    for stationDF in bothHaveData:\n",
    "        stationID[stationDF].to_csv(\"stationData/stationID_\"+str(math.trunc(stationDF))+\".csv\", mode='a', header=False)\n",
    "\n",
    "    print(\"Written station data for year \" + str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
